# DocumentAnalyzer（轻量级中文文档分析工具）

一个可离线运行的中文文档分析工具，提供 GUI（Tkinter），支持对 `.json`/`.jsonl` 文档进行批量/单篇分析，并通过 **A/M 日志闭环**支持人工修正与迭代优化。

---

## 1. 功能概览

- **语料管理**：选择语料目录，扫描 `.jsonl` 文件列表（排除结果日志文件）。
- **单文档分析**：关键词/高频词、轻量实体、三句摘要、文本分类。
- **批量分析**：批量处理目录内所有文档并写入日志（`D_Mark=A`）。
- **人工修正闭环**：界面编辑结果后保存（`D_Mark=M`），回显优先使用最新 M。
- **训练分类器**（可选）：TF-IDF + LogisticRegression，训练标签优先使用 M。
- **结果管理**：打开日志、导出 CSV。

---

## 2. 目录结构

```text
DocumentAnalyzer/
├─ main.py                      # 主程序（GUI）
├─ eval_compare.py              # 实验评测脚本（规则 vs 训练模型）
├─ requirements.txt             # 依赖
└─ examples/
   ├─ 1.jsonl / 2.jsonl ...     # 语料文件
   └─ result/
      ├─ result_log.jsonl       # 结果日志（JSONL）
      └─ export.csv             # 导出示例（可选）
```

> **说明**：项目默认语料目录为 `examples/`，结果目录为 `examples/result/`。

---

## 3. 环境与安装

### 环境要求
- **Python 3.8+**（建议 3.10/3.11）
- **系统**：Windows / macOS / Linux 均可

### 安装依赖
安装最小但完整环境（含训练分类器 + 完整摘要逻辑）：

```bash
pip install -r requirements.txt
```

> **注意**：`tkinter` 为 Python 自带库（Windows/macOS 通常默认包含），无需通过 pip 安装。

---

## 4. 快速开始

### 运行 GUI
在项目根目录执行：

```bash
python main.py
```

### 建议操作流程
1. 点击 **选择目录** → 选择你的语料目录（默认 `examples/`）。
2. 点选左侧文件列表中的某个文件。
3. 点击 **自动分析当前**（生成 A 结果）。
4. 在结果区手工修改内容（如 `ClassLabel`/`Abstract` 等）。
5. 点击 **保存人工更改(M)**（生成 M 结果）。
6. 点击 **训练分类器**（可选）。
7. 再次分析/切换文件，观察回显与预测结果的变化。

---

## 5. 输入格式要求

支持以下两种 JSON 格式：

### A. 完整 JSON 对象
```json
{
  "title": "标题内容",
  "content": "正文内容"
}
```

### B. JSONL（每行一个 JSON 对象）
工具会读取第一条可解析对象：
```jsonl
{"title":"标题1","content":"内容1"}
{"title":"标题2","content":"内容2"}
```

**字段名兼容**：
- 标题支持：`title` / `Title`
- 内容支持：`content` / `Content` / `Document` / `document`

---

## 6. 输出日志（A/M 机制）

**日志路径**：`examples/result/result_log.jsonl`

### A/M 规则
- **A (Auto)**：系统自动分析生成的结果。
- **M (Manual)**：人工修正并点击保存后的结果。
- **回显逻辑**：优先显示该文件最新的 **M** 记录，若无则显示最新 **A**。
- **训练逻辑**：优先使用 **M** 的 `ClassLabel` 作为监督学习标签。

---

## 7. 模型与算法说明

### 分词与预处理
- 使用 `jieba.lcut` 进行分词。
- 过滤停用词、单字及纯数字。

### 关键词提取
- 融合 `TF-IDF` 与 `TextRank` 算法，取 topK 去重合并。

### 摘要提取（三句摘要）
- 基于句子 `TF-IDF` 相似度构建图，运行 `TextRank`/`PageRank`。
- **增强策略**：引入信息密度权重（数字、实体覆盖率）。
- **去冗余**：使用 MMR（最大边界相关法）平衡相关性与多样性。

### 文本分类
- **规则基线**：基于关键词词典打分。
- **训练模型**：TF-IDF 向量化 + 逻辑回归（Logistic Regression）。
- **预测策略**：模型优先，规则兜底。

---

## 8. 实验评测 (eval_compare.py)

该脚本用于比较**规则分类**与**机器学习分类**的效果。

```bash
python eval_compare.py
```

**前提要求（M 标签数量）**：
- 评测时建议至少准备 **M ≥ 20** 条（即至少 20 个语料文件有人工修正后的 `ClassLabel`）。
- 一般来说，**M 的数量越多（人工标签越多），监督信号越充分，分类准确率/宏平均 F1 往往越高**（尤其在类别覆盖更均衡时更明显）。

**逻辑要点**：
1. 从 `result_log.jsonl` 中收集每个文件的最新 M 标签作为真值。
2. 进行 5 折交叉验证（5-Fold Cross Validation）。
3. 输出 **Accuracy** 与 **Macro-F1** 指标。

> **注意**：若某类样本过少，5 折验证会提示样本不足，这属于正常现象。

---

## 9. 常见问题 (FAQ)

**Q1：为什么日志条数增加，但训练样本数不变？** 训练样本按“唯一文件名”构造。日志增长代表对同一文件的多次分析或修正，提升的是标签精度，而非语料规模。

**Q2：没有安装 sklearn/numpy 可以运行吗？** 可以运行 GUI 基本功能，但分类将仅依靠规则，且摘要算法会回退到简易版本。建议安装完整依赖以获得最佳效果。
